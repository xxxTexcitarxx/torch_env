{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00113e75-c7a3-4907-a5cf-0544a52daa16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize Successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "print(\"Initialize Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ccb9877-28c3-4b6e-a5fc-74290b062d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# get device\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fdc41fb-6888-4f2b-8f5c-83a82518bb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define nn class\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # 继承父类的所有__init__方法\n",
    "        self.flatten = nn.Flatten() # flatten last 2 dimensions\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85c6f48b-ebd0-42ef-ad30-84641d4f1351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=1024, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=512, out_features=128, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a573acc4-ccbe-48ce-b120-3849987922bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0960, 0.1036, 0.1067, 0.0951, 0.1068, 0.0978, 0.1073, 0.0918, 0.1014,\n",
      "         0.0935]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "Predicted class: tensor([6], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "# print(logits)\n",
    "print(pred_probab)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "898088e5-c90f-4e33-bec8-a7279b6c3ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=1024, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=512, out_features=128, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[ 0.0178, -0.0089,  0.0056,  ..., -0.0226,  0.0206,  0.0140],\n",
      "        [ 0.0190, -0.0232,  0.0157,  ..., -0.0210,  0.0265,  0.0054]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([0.0036, 0.0003], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([1024, 512]) | Values : tensor([[ 0.0191,  0.0405,  0.0038,  ...,  0.0330,  0.0159, -0.0045],\n",
      "        [-0.0307, -0.0107, -0.0081,  ...,  0.0219, -0.0162, -0.0182]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([1024]) | Values : tensor([-0.0020, -0.0023], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([512, 1024]) | Values : tensor([[ 0.0157,  0.0054, -0.0168,  ...,  0.0239,  0.0199,  0.0207],\n",
      "        [ 0.0172,  0.0220, -0.0264,  ...,  0.0040,  0.0175,  0.0171]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([512]) | Values : tensor([0.0159, 0.0107], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.6.weight | Size: torch.Size([128, 512]) | Values : tensor([[-0.0065, -0.0179,  0.0420,  ...,  0.0263, -0.0139, -0.0337],\n",
      "        [-0.0384,  0.0032, -0.0020,  ...,  0.0243,  0.0101,  0.0406]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.6.bias | Size: torch.Size([128]) | Values : tensor([0.0063, 0.0354], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.8.weight | Size: torch.Size([10, 128]) | Values : tensor([[-0.0882, -0.0651, -0.0704,  0.0786, -0.0583, -0.0013, -0.0725,  0.0725,\n",
      "          0.0443,  0.0087,  0.0480, -0.0680, -0.0630, -0.0544,  0.0121, -0.0521,\n",
      "          0.0817, -0.0454, -0.0309, -0.0448, -0.0598, -0.0436,  0.0049,  0.0649,\n",
      "          0.0640,  0.0676, -0.0818,  0.0875, -0.0463,  0.0269, -0.0049,  0.0862,\n",
      "          0.0510, -0.0804, -0.0716,  0.0227, -0.0530, -0.0528,  0.0244,  0.0173,\n",
      "         -0.0109,  0.0252,  0.0262,  0.0218,  0.0566,  0.0105,  0.0417, -0.0341,\n",
      "          0.0267,  0.0701, -0.0263,  0.0838,  0.0014,  0.0677,  0.0067,  0.0865,\n",
      "          0.0312, -0.0781,  0.0249,  0.0270, -0.0190,  0.0332,  0.0509,  0.0183,\n",
      "          0.0391, -0.0576, -0.0189, -0.0570,  0.0003, -0.0198, -0.0383, -0.0755,\n",
      "          0.0775,  0.0327,  0.0678,  0.0511,  0.0003, -0.0425, -0.0344, -0.0207,\n",
      "          0.0845,  0.0183,  0.0406, -0.0125,  0.0697, -0.0872, -0.0418, -0.0548,\n",
      "          0.0884,  0.0709, -0.0290,  0.0045, -0.0702, -0.0526,  0.0229, -0.0268,\n",
      "          0.0706,  0.0482,  0.0504, -0.0519, -0.0148,  0.0624, -0.0513,  0.0824,\n",
      "         -0.0587, -0.0084, -0.0445,  0.0061,  0.0227, -0.0158, -0.0836, -0.0660,\n",
      "         -0.0621, -0.0199,  0.0468,  0.0695, -0.0196, -0.0669, -0.0104, -0.0763,\n",
      "         -0.0220,  0.0542, -0.0851,  0.0623, -0.0692,  0.0123,  0.0134,  0.0560],\n",
      "        [ 0.0873,  0.0705, -0.0550,  0.0263, -0.0871, -0.0050,  0.0172,  0.0043,\n",
      "         -0.0813,  0.0649, -0.0696, -0.0357, -0.0527,  0.0085, -0.0706, -0.0151,\n",
      "          0.0848, -0.0321,  0.0460,  0.0810,  0.0844, -0.0501, -0.0658,  0.0414,\n",
      "          0.0431, -0.0654, -0.0352,  0.0053, -0.0844,  0.0773, -0.0252, -0.0150,\n",
      "          0.0380, -0.0005, -0.0306,  0.0673, -0.0413,  0.0391,  0.0836, -0.0254,\n",
      "         -0.0637,  0.0699,  0.0288, -0.0851,  0.0484, -0.0828,  0.0644,  0.0451,\n",
      "          0.0431,  0.0332,  0.0395,  0.0544, -0.0488, -0.0451, -0.0540,  0.0230,\n",
      "         -0.0171, -0.0631,  0.0695,  0.0527, -0.0369,  0.0848,  0.0641,  0.0681,\n",
      "          0.0730,  0.0737, -0.0851, -0.0077, -0.0014, -0.0290, -0.0409, -0.0254,\n",
      "          0.0521,  0.0744,  0.0149,  0.0302, -0.0667, -0.0317,  0.0133,  0.0340,\n",
      "          0.0605,  0.0185,  0.0428, -0.0344, -0.0763, -0.0395,  0.0812, -0.0323,\n",
      "         -0.0763,  0.0187,  0.0671,  0.0756,  0.0036, -0.0405,  0.0179,  0.0736,\n",
      "         -0.0138, -0.0724,  0.0638,  0.0549,  0.0762,  0.0146,  0.0662, -0.0673,\n",
      "         -0.0599,  0.0272, -0.0167,  0.0033,  0.0439,  0.0111, -0.0081,  0.0124,\n",
      "         -0.0137,  0.0524, -0.0639, -0.0426, -0.0839,  0.0259, -0.0319,  0.0772,\n",
      "          0.0142, -0.0066, -0.0615,  0.0382, -0.0461, -0.0699,  0.0018,  0.0330]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.8.bias | Size: torch.Size([10]) | Values : tensor([-0.0503,  0.0463], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c5f062-1d45-4669-bbce-ed07113a2935",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
